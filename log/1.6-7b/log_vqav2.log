Running target_layer_idx=29
Mask ratio=0.2
Executing: python _eval.py  --model llava_new_1.6_7 --task vqav2  --max_sample 1000 --lora_name vqav2-29-llava_new_1.6_7-0.2 --batch_size 1 --attn_layer_idx 17 --target_layer_idx 29 --result_path result_0.json --mask_ratio 0.2 
nohup: ignoring input
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.embeddings.class_embedding: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.embeddings.patch_embedding.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.embeddings.position_embedding.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.pre_layrnorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.pre_layrnorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.post_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.post_layernorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|      | 1/3 [00:05<00:10,  5.08s/it]Loading checkpoint shards:  67%|   | 2/3 [00:10<00:05,  5.04s/it]Loading checkpoint shards: 100%|| 3/3 [00:15<00:00,  5.43s/it]Loading checkpoint shards: 100%|| 3/3 [00:15<00:00,  5.33s/it]
Processing:   0%|                                                          | 0/1000 [00:00<?, ?it/s]/ai/teacher/ssz/layer_task/transformers/src/transformers/generation/configuration_utils.py:788: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.
  warnings.warn(
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
Processing:   0%|                                                  | 1/1000 [00:00<16:20,  1.02it/s]Processing:   0%|                                                  | 2/1000 [00:01<11:25,  1.46it/s]Processing:   0%|                                                 | 3/1000 [00:01<09:52,  1.68it/s]Processing:   0%|                                                 | 4/1000 [00:02<09:45,  1.70it/s]Processing:   0%|                                                 | 5/1000 [00:02<08:41,  1.91it/s]Processing:   1%|                                                 | 6/1000 [00:03<08:19,  1.99it/s]Processing:   1%|                                                 | 7/1000 [00:03<08:00,  2.07it/s]Processing:   1%|                                                 | 8/1000 [00:04<08:00,  2.07it/s]Processing:   1%|                                                 | 9/1000 [00:04<08:04,  2.04it/s]Processing:   1%|                                                | 10/1000 [00:05<09:23,  1.76it/s]Processing:   1%|                                                | 11/1000 [00:06<09:02,  1.82it/s]Processing:   1%|                                                | 12/1000 [00:06<08:55,  1.84it/s]Processing:   1%|                                                | 13/1000 [00:07<09:04,  1.81it/s]Processing:   1%|                                                | 14/1000 [00:07<08:24,  1.95it/s]Processing:   2%|                                                | 15/1000 [00:07<07:51,  2.09it/s]Processing:   2%|                                                | 16/1000 [00:08<07:53,  2.08it/s]Processing:   2%|                                                | 17/1000 [00:08<07:30,  2.18it/s]Processing:   2%|                                                | 18/1000 [00:09<07:30,  2.18it/s]Processing:   2%|                                                | 19/1000 [00:09<07:21,  2.22it/s]Processing:   2%|                                                | 19/1000 [00:10<08:47,  1.86it/s]
Traceback (most recent call last):
  File "/ai/teacher/ssz/layer_task/mllms_know/_eval.py", line 253, in <module>
    _eval(args)
  File "/ai/teacher/ssz/layer_task/mllms_know/_eval.py", line 184, in _eval
    output_ids = model.generate(
  File "/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ai/teacher/ssz/layer_task/mllms_know/llava/model/language_model/llava_llama.py", line 151, in generate
    return super().generate(
  File "/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/ai/teacher/ssz/layer_task/mllms_know/llava/model/language_model/generate.py", line 2082, in generate
    result = self._dola_decoding(
  File "/ai/teacher/ssz/layer_task/mllms_know/llava/model/language_model/generate.py", line 2598, in _dola_decoding
    next_token_logits, premature_layer = _dola_select_contrast(
  File "/ai/teacher/ssz/layer_task/mllms_know/llava/model/language_model/generate.py", line 4707, in _dola_select_contrast
    premature_layer = candidate_premature_layers[int(js_divs.argmax().cpu().item())]
KeyboardInterrupt
Running target_layer_idx=29
Mask ratio=0.2
Executing: python _eval.py  --model llava_new_1.6_7 --task vqav2  --max_sample 1000 --lora_name vqav2-29-llava_new_1.6_7-0.2 --batch_size 1 --attn_layer_idx 17 --target_layer_idx 29 --result_path result_0.json --mask_ratio 0.2 
nohup: ignoring input
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.embeddings.class_embedding: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.embeddings.patch_embedding.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.embeddings.position_embedding.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.pre_layrnorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.pre_layrnorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.0.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.1.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.2.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.3.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.4.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.5.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.6.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.7.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.8.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.9.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.10.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.11.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.12.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.13.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.14.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.15.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.16.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.17.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.18.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.19.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.20.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.21.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.22.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.encoder.layers.23.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.post_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
/root/miniconda3/envs/mllms/lib/python3.10/site-packages/torch/nn/modules/module.py:2397: UserWarning: for vision_model.post_layernorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|      | 1/3 [00:05<00:10,  5.13s/it]Loading checkpoint shards:  67%|   | 2/3 [00:10<00:05,  5.15s/it]Loading checkpoint shards: 100%|| 3/3 [00:16<00:00,  5.50s/it]Loading checkpoint shards: 100%|| 3/3 [00:16<00:00,  5.41s/it]
Processing:   0%|                                                          | 0/1000 [00:00<?, ?it/s]/ai/teacher/ssz/layer_task/transformers/src/transformers/generation/configuration_utils.py:788: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.
  warnings.warn(
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
Processing:   0%|                                                  | 1/1000 [00:01<16:56,  1.02s/it]Processing:   0%|                                                  | 2/1000 [00:01<11:46,  1.41it/s]Processing:   0%|                                                 | 3/1000 [00:01<10:03,  1.65it/s]Processing:   0%|                                               | 4/1000 [00:26<2:47:18, 10.08s/it]Processing:   0%|                                               | 5/1000 [00:27<1:49:47,  6.62s/it]Processing:   1%|                                               | 6/1000 [00:27<1:15:02,  4.53s/it]Processing:   1%|                                                 | 7/1000 [00:28<53:08,  3.21s/it]Processing:   1%|                                                 | 8/1000 [00:28<38:46,  2.35s/it]Processing:   1%|                                                 | 9/1000 [00:29<29:11,  1.77s/it]Processing:   1%|                                                | 10/1000 [00:29<23:00,  1.39s/it]Processing:   1%|                                                | 11/1000 [00:30<18:33,  1.13s/it]Processing:   1%|                                                | 12/1000 [00:30<15:34,  1.06it/s]Processing:   1%|                                                | 13/1000 [00:31<13:40,  1.20it/s]Processing:   1%|                                                | 14/1000 [00:31<11:39,  1.41it/s]Processing:   2%|                                                | 15/1000 [00:32<10:08,  1.62it/s]Processing:   2%|                                                | 16/1000 [00:32<09:33,  1.72it/s]Processing:   2%|                                                | 17/1000 [00:32<08:37,  1.90it/s]Processing:   2%|                                                | 18/1000 [00:33<08:19,  1.97it/s]Processing:   2%|                                                | 19/1000 [00:33<07:55,  2.06it/s]Processing:   2%|                                                | 20/1000 [00:34<07:59,  2.04it/s]Processing:   2%|                                                | 21/1000 [00:34<08:05,  2.02it/s]Processing:   2%|                                                | 22/1000 [00:35<08:14,  1.98it/s]Processing:   2%|                                               | 23/1000 [00:36<09:10,  1.78it/s]Processing:   2%|                                               | 24/1000 [00:36<10:27,  1.55it/s]Processing:   2%|                                               | 25/1000 [00:37<10:06,  1.61it/s]Processing:   3%|                                               | 26/1000 [00:37<09:31,  1.70it/s]Processing:   3%|                                               | 27/1000 [00:38<08:59,  1.80it/s]Processing:   3%|                                               | 28/1000 [00:38<08:29,  1.91it/s]Processing:   3%|                                               | 29/1000 [00:39<08:11,  1.97it/s]Processing:   3%|                                               | 30/1000 [00:39<08:18,  1.95it/s]Processing:   3%|                                               | 31/1000 [00:40<08:03,  2.00it/s]Processing:   3%|                                               | 32/1000 [00:40<07:42,  2.09it/s]Processing:   3%|                                               | 33/1000 [00:41<07:38,  2.11it/s]Processing:   3%|                                               | 34/1000 [00:42<09:21,  1.72it/s]Processing:   4%|                                               | 35/1000 [00:42<09:00,  1.79it/s]Processing:   4%|                                               | 36/1000 [00:43<08:31,  1.88it/s]Processing:   4%|                                               | 37/1000 [00:43<08:18,  1.93it/s]Processing:   4%|                                               | 38/1000 [00:44<08:15,  1.94it/s]Processing:   4%|                                               | 39/1000 [00:44<09:37,  1.66it/s]Processing:   4%|                                               | 40/1000 [00:45<09:43,  1.64it/s]Processing:   4%|                                               | 41/1000 [00:46<09:23,  1.70it/s]Processing:   4%|                                               | 42/1000 [00:46<09:00,  1.77it/s]Processing:   4%|                                               | 43/1000 [00:47<08:44,  1.82it/s]Processing:   4%|                                              | 44/1000 [00:47<08:32,  1.87it/s]Processing:   4%|                                              | 45/1000 [00:48<08:42,  1.83it/s]Processing:   5%|                                              | 46/1000 [00:48<08:25,  1.89it/s]Processing:   5%|                                              | 47/1000 [00:49<08:26,  1.88it/s]Processing:   5%|                                              | 48/1000 [00:49<08:03,  1.97it/s]Processing:   5%|                                              | 49/1000 [00:50<07:52,  2.01it/s]Processing:   5%|                                              | 50/1000 [00:50<07:42,  2.05it/s]Processing:   5%|                                              | 51/1000 [00:51<07:48,  2.03it/s]Processing:   5%|                                              | 52/1000 [00:51<07:59,  1.98it/s]Processing:   5%|                                              | 53/1000 [00:52<07:54,  2.00it/s]Processing:   5%|                                              | 54/1000 [00:52<08:12,  1.92it/s]Processing:   6%|                                              | 55/1000 [00:53<08:18,  1.90it/s]Processing:   6%|                                              | 56/1000 [00:53<08:21,  1.88it/s]Processing:   6%|                                              | 57/1000 [00:54<07:51,  2.00it/s]Processing:   6%|                                              | 58/1000 [00:54<07:47,  2.01it/s]Processing:   6%|                                              | 59/1000 [00:55<07:38,  2.05it/s]Processing:   6%|                                              | 60/1000 [00:55<07:52,  1.99it/s]Processing:   6%|                                              | 61/1000 [00:56<08:03,  1.94it/s]Processing:   6%|                                              | 62/1000 [00:56<07:48,  2.00it/s]Processing:   6%|                                              | 63/1000 [00:57<09:06,  1.71it/s]Processing:   6%|                                             | 64/1000 [00:57<08:45,  1.78it/s]Processing:   6%|                                             | 65/1000 [00:58<08:17,  1.88it/s]Processing:   7%|                                             | 66/1000 [00:58<07:58,  1.95it/s]Processing:   7%|                                             | 67/1000 [00:59<07:44,  2.01it/s]Processing:   7%|                                             | 68/1000 [00:59<07:43,  2.01it/s]Processing:   7%|                                             | 69/1000 [01:00<08:28,  1.83it/s]Processing:   7%|                                             | 70/1000 [01:01<08:53,  1.74it/s]Processing:   7%|                                             | 71/1000 [01:01<08:51,  1.75it/s]Processing:   7%|                                             | 72/1000 [01:02<08:32,  1.81it/s]Processing:   7%|                                             | 73/1000 [01:02<08:19,  1.86it/s]Processing:   7%|                                             | 74/1000 [01:03<08:53,  1.73it/s]Processing:   8%|                                             | 75/1000 [01:03<08:33,  1.80it/s]Processing:   8%|                                             | 76/1000 [01:04<08:04,  1.91it/s]Processing:   8%|                                             | 77/1000 [01:04<07:56,  1.94it/s]Processing:   8%|                                             | 78/1000 [01:05<08:07,  1.89it/s]Processing:   8%|                                             | 79/1000 [01:05<07:56,  1.93it/s]Processing:   8%|                                             | 80/1000 [01:06<07:24,  2.07it/s]Processing:   8%|                                             | 81/1000 [01:06<07:36,  2.01it/s]Processing:   8%|                                             | 82/1000 [01:07<07:31,  2.03it/s]Processing:   8%|                                             | 83/1000 [01:07<07:13,  2.12it/s]Processing:   8%|                                             | 84/1000 [01:08<07:17,  2.09it/s]Processing:   8%|                                            | 85/1000 [01:08<07:03,  2.16it/s]Processing:   9%|                                            | 86/1000 [01:09<07:10,  2.12it/s]Processing:   9%|                                            | 87/1000 [01:09<06:57,  2.19it/s]Processing:   9%|                                            | 88/1000 [01:10<07:05,  2.14it/s]Processing:   9%|                                            | 89/1000 [01:10<07:10,  2.12it/s]Processing:   9%|                                            | 90/1000 [01:11<07:08,  2.12it/s]Processing:   9%|                                            | 91/1000 [01:11<07:06,  2.13it/s]Processing:   9%|                                            | 92/1000 [01:12<07:44,  1.96it/s]Processing:   9%|                                            | 93/1000 [01:12<08:15,  1.83it/s]Processing:   9%|                                            | 94/1000 [01:13<09:08,  1.65it/s]Processing:  10%|                                            | 95/1000 [01:14<09:24,  1.60it/s]Processing:  10%|                                            | 96/1000 [01:14<09:40,  1.56it/s]Processing:  10%|                                            | 97/1000 [01:15<08:42,  1.73it/s]Processing:  10%|                                            | 98/1000 [01:15<08:11,  1.84it/s]Processing:  10%|                                            | 99/1000 [01:16<07:33,  1.99it/s]Processing:  10%|                                           | 100/1000 [01:16<07:30,  2.00it/s]Processing:  10%|                                           | 101/1000 [01:17<07:10,  2.09it/s]Processing:  10%|                                           | 102/1000 [01:17<06:56,  2.16it/s]Processing:  10%|                                           | 103/1000 [01:17<06:56,  2.15it/s]Processing:  10%|                                           | 104/1000 [01:18<06:56,  2.15it/s]Processing:  10%|                                           | 105/1000 [01:18<06:54,  2.16it/s]Processing:  11%|                                           | 106/1000 [01:19<06:55,  2.15it/s]Processing:  11%|                                          | 107/1000 [01:19<07:13,  2.06it/s]Processing:  11%|                                          | 108/1000 [01:20<06:47,  2.19it/s]Processing:  11%|                                          | 109/1000 [01:20<06:28,  2.29it/s]Processing:  11%|                                          | 110/1000 [01:21<06:25,  2.31it/s]Processing:  11%|                                          | 111/1000 [01:21<06:43,  2.20it/s]Processing:  11%|                                          | 112/1000 [01:21<06:32,  2.26it/s]Processing:  11%|                                          | 113/1000 [01:22<07:44,  1.91it/s]Processing:  11%|                                          | 114/1000 [01:23<07:38,  1.93it/s]Processing:  12%|                                          | 115/1000 [01:23<07:03,  2.09it/s]Processing:  12%|                                          | 116/1000 [01:23<06:44,  2.19it/s]Processing:  12%|                                          | 117/1000 [01:24<07:22,  1.99it/s]Processing:  12%|                                          | 118/1000 [01:25<07:14,  2.03it/s]Processing:  12%|                                          | 119/1000 [01:25<06:42,  2.19it/s]Processing:  12%|                                          | 120/1000 [01:25<07:10,  2.04it/s]Processing:  12%|                                          | 121/1000 [01:26<06:49,  2.15it/s]Processing:  12%|                                          | 122/1000 [01:26<06:22,  2.30it/s]Processing:  12%|                                          | 123/1000 [01:27<06:18,  2.32it/s]Processing:  12%|                                          | 124/1000 [01:27<06:19,  2.31it/s]Processing:  12%|                                          | 125/1000 [01:28<07:26,  1.96it/s]Processing:  13%|                                          | 126/1000 [01:28<08:00,  1.82it/s]Processing:  13%|                                          | 127/1000 [01:29<08:36,  1.69it/s]Processing:  13%|                                         | 128/1000 [01:30<09:08,  1.59it/s]Processing:  13%|                                         | 129/1000 [01:30<08:56,  1.62it/s]Processing:  13%|                                         | 130/1000 [01:31<09:20,  1.55it/s]Processing:  13%|                                         | 131/1000 [01:32<09:58,  1.45it/s]Processing:  13%|                                         | 132/1000 [01:33<09:30,  1.52it/s]Processing:  13%|                                         | 133/1000 [01:33<09:43,  1.49it/s]Processing:  13%|                                         | 134/1000 [01:34<09:52,  1.46it/s]Processing:  14%|                                         | 135/1000 [01:35<09:58,  1.45it/s]Processing:  14%|                                         | 136/1000 [01:35<09:56,  1.45it/s]Processing:  14%|                                         | 137/1000 [01:36<08:59,  1.60it/s]Processing:  14%|                                         | 138/1000 [01:36<08:24,  1.71it/s]Processing:  14%|                                         | 139/1000 [01:37<08:26,  1.70it/s]Processing:  14%|                                         | 140/1000 [01:37<07:51,  1.82it/s]Processing:  14%|                                         | 141/1000 [01:38<07:17,  1.97it/s]Processing:  14%|                                         | 142/1000 [01:38<07:06,  2.01it/s]Processing:  14%|                                         | 143/1000 [01:39<06:49,  2.10it/s]Processing:  14%|                                         | 144/1000 [01:39<07:01,  2.03it/s]Processing:  14%|                                         | 145/1000 [01:40<06:47,  2.10it/s]Processing:  15%|                                         | 146/1000 [01:40<06:56,  2.05it/s]Processing:  15%|                                         | 147/1000 [01:41<07:57,  1.79it/s]Processing:  15%|                                         | 148/1000 [01:41<07:53,  1.80it/s]Processing:  15%|                                        | 149/1000 [01:42<07:34,  1.87it/s]Processing:  15%|                                        | 150/1000 [01:42<07:28,  1.90it/s]Processing:  15%|                                        | 151/1000 [01:43<07:12,  1.96it/s]Processing:  15%|                                        | 152/1000 [01:43<07:01,  2.01it/s]Processing:  15%|                                        | 153/1000 [01:44<08:00,  1.76it/s]Processing:  15%|                                        | 154/1000 [01:45<07:34,  1.86it/s]Processing:  16%|                                        | 155/1000 [01:45<07:26,  1.89it/s]Processing:  16%|                                        | 156/1000 [01:46<07:39,  1.84it/s]Processing:  16%|                                        | 157/1000 [01:46<08:23,  1.68it/s]Processing:  16%|                                        | 158/1000 [01:47<07:59,  1.75it/s]Processing:  16%|                                        | 159/1000 [01:47<06:53,  2.04it/s]Processing:  16%|                                        | 160/1000 [01:48<06:58,  2.01it/s]Processing:  16%|                                        | 161/1000 [01:48<06:50,  2.05it/s]Processing:  16%|                                        | 162/1000 [01:49<06:33,  2.13it/s]Processing:  16%|                                        | 163/1000 [01:49<06:44,  2.07it/s]Processing:  16%|                                        | 164/1000 [01:50<06:39,  2.09it/s]Processing:  16%|                                        | 165/1000 [01:50<06:27,  2.15it/s]Processing:  17%|                                        | 166/1000 [01:51<06:33,  2.12it/s]Processing:  17%|                                        | 167/1000 [01:51<06:23,  2.17it/s]Processing:  17%|                                        | 168/1000 [01:51<06:36,  2.10it/s]Processing:  17%|                                        | 169/1000 [01:52<06:51,  2.02it/s]Processing:  17%|                                       | 170/1000 [01:53<06:56,  1.99it/s]Processing:  17%|                                       | 171/1000 [01:53<06:46,  2.04it/s]Processing:  17%|                                       | 172/1000 [01:53<06:39,  2.07it/s]Processing:  17%|                                       | 173/1000 [01:54<06:53,  2.00it/s]Processing:  17%|                                       | 174/1000 [01:54<06:52,  2.00it/s]Processing:  18%|                                       | 175/1000 [01:55<07:13,  1.90it/s]Processing:  18%|                                       | 176/1000 [01:56<07:26,  1.84it/s]Processing:  18%|                                       | 177/1000 [01:56<07:24,  1.85it/s]Processing:  18%|                                       | 178/1000 [01:57<07:13,  1.90it/s]Processing:  18%|                                       | 179/1000 [01:57<06:42,  2.04it/s]Processing:  18%|                                       | 180/1000 [01:58<06:36,  2.07it/s]Processing:  18%|                                       | 181/1000 [01:58<06:38,  2.06it/s]Processing:  18%|                                       | 182/1000 [01:59<06:39,  2.05it/s]Processing:  18%|                                       | 183/1000 [01:59<06:30,  2.09it/s]Processing:  18%|                                       | 184/1000 [01:59<06:28,  2.10it/s]Processing:  18%|                                       | 185/1000 [02:00<07:20,  1.85it/s]Processing:  19%|                                       | 186/1000 [02:01<07:35,  1.79it/s]Processing:  19%|                                       | 187/1000 [02:01<08:06,  1.67it/s]Processing:  19%|                                       | 188/1000 [02:02<07:34,  1.79it/s]Processing:  19%|                                       | 189/1000 [02:02<07:22,  1.83it/s]Processing:  19%|                                       | 190/1000 [02:03<07:13,  1.87it/s]Processing:  19%|                                      | 191/1000 [02:03<07:11,  1.88it/s]Processing:  19%|                                      | 192/1000 [02:04<06:54,  1.95it/s]Processing:  19%|                                      | 193/1000 [02:04<06:37,  2.03it/s]Processing:  19%|                                      | 194/1000 [02:05<07:04,  1.90it/s]Processing:  20%|                                      | 195/1000 [02:06<07:01,  1.91it/s]Processing:  20%|                                      | 196/1000 [02:06<06:45,  1.98it/s]Processing:  20%|                                      | 197/1000 [02:06<06:36,  2.03it/s]Processing:  20%|                                      | 198/1000 [02:07<05:29,  2.44it/s]Processing:  20%|                                      | 199/1000 [02:07<04:41,  2.85it/s]Processing:  20%|                                      | 200/1000 [02:07<04:05,  3.25it/s]Processing:  20%|                                      | 201/1000 [02:07<03:42,  3.59it/s]Processing:  20%|                                      | 202/1000 [02:07<03:22,  3.94it/s]Processing:  20%|                                      | 203/1000 [02:08<03:12,  4.14it/s]Processing:  20%|                                      | 204/1000 [02:08<03:01,  4.38it/s]Processing:  20%|                                      | 205/1000 [02:08<02:56,  4.51it/s]Processing:  21%|                                      | 206/1000 [02:08<03:11,  4.15it/s]Processing:  21%|                                      | 207/1000 [02:09<04:41,  2.81it/s]Processing:  21%|                                      | 208/1000 [02:10<05:28,  2.41it/s]Processing:  21%|                                      | 209/1000 [02:10<06:14,  2.11it/s]Processing:  21%|                                      | 210/1000 [02:11<06:28,  2.03it/s]Processing:  21%|                                     | 211/1000 [02:11<06:08,  2.14it/s]Processing:  21%|                                     | 212/1000 [02:12<06:10,  2.13it/s]Processing:  21%|                                     | 213/1000 [02:12<06:02,  2.17it/s]Processing:  21%|                                     | 214/1000 [02:12<05:59,  2.19it/s]Processing:  22%|                                     | 215/1000 [02:13<05:57,  2.19it/s]Processing:  22%|                                     | 216/1000 [02:13<05:50,  2.24it/s]Processing:  22%|                                     | 217/1000 [02:14<05:58,  2.19it/s]Processing:  22%|                                     | 218/1000 [02:14<06:00,  2.17it/s]Processing:  22%|                                     | 219/1000 [02:15<06:18,  2.06it/s]Processing:  22%|                                     | 220/1000 [02:15<06:13,  2.09it/s]Processing:  22%|                                     | 221/1000 [02:16<06:11,  2.10it/s]Processing:  22%|                                     | 222/1000 [02:16<06:56,  1.87it/s]Processing:  22%|                                     | 223/1000 [02:17<06:45,  1.92it/s]Processing:  22%|                                     | 224/1000 [02:17<06:49,  1.90it/s]Processing:  22%|                                     | 225/1000 [02:18<07:20,  1.76it/s]Processing:  23%|                                     | 226/1000 [02:19<06:57,  1.85it/s]Processing:  23%|                                     | 227/1000 [02:19<07:14,  1.78it/s]Processing:  23%|                                     | 228/1000 [02:20<07:17,  1.76it/s]Processing:  23%|                                     | 229/1000 [02:20<06:44,  1.90it/s]Processing:  23%|                                     | 230/1000 [02:21<06:26,  1.99it/s]Processing:  23%|                                     | 231/1000 [02:21<06:31,  1.96it/s]Processing:  23%|                                    | 232/1000 [02:22<06:22,  2.01it/s]Processing:  23%|                                    | 233/1000 [02:22<07:23,  1.73it/s]Processing:  23%|                                    | 234/1000 [02:23<07:34,  1.69it/s]Processing:  24%|                                    | 235/1000 [02:24<09:01,  1.41it/s]Processing:  24%|                                    | 236/1000 [02:25<08:52,  1.44it/s]Processing:  24%|                                    | 237/1000 [02:25<08:19,  1.53it/s]Processing:  24%|                                    | 238/1000 [02:26<07:50,  1.62it/s]Processing:  24%|                                    | 239/1000 [02:26<07:20,  1.73it/s]Processing:  24%|                                    | 240/1000 [02:27<06:52,  1.84it/s]Processing:  24%|                                    | 241/1000 [02:27<06:49,  1.85it/s]Processing:  24%|                                    | 242/1000 [02:28<06:41,  1.89it/s]Processing:  24%|                                    | 243/1000 [02:28<06:37,  1.90it/s]Processing:  24%|                                    | 244/1000 [02:29<06:33,  1.92it/s]Processing:  24%|                                    | 245/1000 [02:29<06:29,  1.94it/s]Processing:  25%|                                    | 246/1000 [02:30<06:16,  2.00it/s]Processing:  25%|                                    | 247/1000 [02:30<06:28,  1.94it/s]Processing:  25%|                                    | 248/1000 [02:31<06:39,  1.88it/s]Processing:  25%|                                    | 249/1000 [02:31<06:50,  1.83it/s]Processing:  25%|                                    | 250/1000 [02:32<06:44,  1.85it/s]Processing:  25%|                                    | 251/1000 [02:32<06:32,  1.91it/s]Processing:  25%|                                    | 252/1000 [02:33<06:40,  1.87it/s]Processing:  25%|                                   | 253/1000 [02:34<06:24,  1.94it/s]Processing:  25%|                                   | 254/1000 [02:34<06:23,  1.95it/s]Processing:  26%|                                   | 255/1000 [02:35<06:27,  1.92it/s]Processing:  26%|                                   | 256/1000 [02:35<06:29,  1.91it/s]Processing:  26%|                                   | 257/1000 [02:36<06:13,  1.99it/s]Processing:  26%|                                   | 258/1000 [02:36<06:04,  2.03it/s]Processing:  26%|                                   | 259/1000 [02:37<06:17,  1.96it/s]Processing:  26%|                                   | 260/1000 [02:37<06:18,  1.96it/s]Processing:  26%|                                   | 261/1000 [02:38<06:05,  2.02it/s]Processing:  26%|                                   | 262/1000 [02:38<05:50,  2.11it/s]Processing:  26%|                                   | 263/1000 [02:38<05:56,  2.06it/s]Processing:  26%|                                   | 264/1000 [02:39<06:18,  1.95it/s]Processing:  26%|                                   | 265/1000 [02:40<06:21,  1.93it/s]Processing:  27%|                                   | 266/1000 [02:40<06:28,  1.89it/s]Processing:  27%|                                   | 267/1000 [02:41<06:13,  1.96it/s]Processing:  27%|                                   | 268/1000 [02:41<06:08,  1.99it/s]Processing:  27%|                                   | 269/1000 [02:42<06:01,  2.02it/s]Processing:  27%|                                   | 270/1000 [02:42<05:55,  2.06it/s]Processing:  27%|                                   | 271/1000 [02:43<06:05,  1.99it/s]Processing:  27%|                                   | 272/1000 [02:43<06:13,  1.95it/s]Processing:  27%|                                   | 273/1000 [02:44<05:58,  2.03it/s]Processing:  27%|                                  | 274/1000 [02:44<05:57,  2.03it/s]Processing:  28%|                                  | 275/1000 [02:45<06:22,  1.89it/s]Processing:  28%|                                  | 276/1000 [02:45<06:39,  1.81it/s]Processing:  28%|                                  | 277/1000 [02:46<08:15,  1.46it/s]Processing:  28%|                                  | 278/1000 [02:47<08:14,  1.46it/s]Processing:  28%|                                  | 279/1000 [02:48<08:13,  1.46it/s]Processing:  28%|                                  | 280/1000 [02:48<08:11,  1.47it/s]Processing:  28%|                                  | 281/1000 [02:49<07:35,  1.58it/s]Processing:  28%|                                  | 282/1000 [02:49<06:56,  1.72it/s]Processing:  28%|                                  | 283/1000 [02:50<06:19,  1.89it/s]Processing:  28%|                                  | 284/1000 [02:50<05:57,  2.00it/s]Processing:  28%|                                  | 285/1000 [02:51<05:41,  2.10it/s]Processing:  29%|                                  | 286/1000 [02:51<05:46,  2.06it/s]Processing:  29%|                                  | 287/1000 [02:52<05:42,  2.08it/s]Processing:  29%|                                  | 288/1000 [02:52<06:00,  1.98it/s]Processing:  29%|                                  | 289/1000 [02:53<05:52,  2.02it/s]Processing:  29%|                                  | 290/1000 [02:53<05:47,  2.04it/s]Processing:  29%|                                  | 291/1000 [02:54<05:51,  2.02it/s]Processing:  29%|                                  | 292/1000 [02:54<05:57,  1.98it/s]Processing:  29%|                                  | 293/1000 [02:55<05:51,  2.01it/s]Processing:  29%|                                  | 294/1000 [02:55<05:54,  1.99it/s]Processing:  30%|                                 | 295/1000 [02:56<05:56,  1.98it/s]Processing:  30%|                                 | 296/1000 [02:56<07:16,  1.61it/s]Processing:  30%|                                 | 297/1000 [02:57<08:02,  1.46it/s]Processing:  30%|                                 | 298/1000 [02:58<07:14,  1.62it/s]Processing:  30%|                                 | 299/1000 [02:59<07:55,  1.47it/s]Processing:  30%|                                 | 300/1000 [02:59<07:41,  1.52it/s]Processing:  30%|                                 | 301/1000 [03:00<07:31,  1.55it/s]Processing:  30%|                                 | 302/1000 [03:01<07:42,  1.51it/s]Processing:  30%|                                 | 303/1000 [03:01<06:56,  1.67it/s]Processing:  30%|                                 | 304/1000 [03:01<06:38,  1.75it/s]Processing:  30%|                                 | 305/1000 [03:02<06:10,  1.88it/s]Processing:  31%|                                 | 306/1000 [03:02<05:50,  1.98it/s]Processing:  31%|                                 | 307/1000 [03:03<05:46,  2.00it/s]Processing:  31%|                                 | 308/1000 [03:03<05:48,  1.98it/s]Processing:  31%|                                 | 309/1000 [03:04<05:49,  1.98it/s]Processing:  31%|                                 | 310/1000 [03:04<05:32,  2.08it/s]Processing:  31%|                                 | 311/1000 [03:05<05:33,  2.07it/s]Processing:  31%|                                 | 312/1000 [03:05<05:32,  2.07it/s]Processing:  31%|                                 | 313/1000 [03:06<06:27,  1.77it/s]Processing:  31%|                                 | 314/1000 [03:06<05:54,  1.93it/s]Processing:  32%|                                 | 315/1000 [03:07<05:45,  1.98it/s]Processing:  32%|                                | 316/1000 [03:08<06:53,  1.65it/s]Processing:  32%|                                | 317/1000 [03:08<06:29,  1.75it/s]Processing:  32%|                                | 318/1000 [03:09<06:27,  1.76it/s]Processing:  32%|                                | 319/1000 [03:09<05:59,  1.90it/s]Processing:  32%|                                | 320/1000 [03:10<05:35,  2.03it/s]Processing:  32%|                                | 321/1000 [03:10<05:29,  2.06it/s]Processing:  32%|                                | 322/1000 [03:11<05:26,  2.08it/s]Processing:  32%|                                | 323/1000 [03:11<05:31,  2.05it/s]Processing:  32%|                                | 324/1000 [03:12<06:44,  1.67it/s]Processing:  32%|                                | 325/1000 [03:12<06:14,  1.80it/s]Processing:  33%|                                | 326/1000 [03:13<05:45,  1.95it/s]Processing:  33%|                                | 327/1000 [03:13<05:41,  1.97it/s]Processing:  33%|                                | 328/1000 [03:14<05:25,  2.06it/s]Processing:  33%|                                | 329/1000 [03:14<05:14,  2.13it/s]Processing:  33%|                                | 330/1000 [03:15<05:10,  2.16it/s]Processing:  33%|                                | 331/1000 [03:15<05:56,  1.88it/s]Processing:  33%|                                | 332/1000 [03:16<05:42,  1.95it/s]Processing:  33%|                                | 333/1000 [03:16<05:22,  2.07it/s]Processing:  33%|                                | 334/1000 [03:17<05:42,  1.94it/s]Processing:  34%|                                | 335/1000 [03:17<05:51,  1.89it/s]Processing:  34%|                               | 336/1000 [03:18<05:33,  1.99it/s]Processing:  34%|                               | 337/1000 [03:18<05:44,  1.93it/s]Processing:  34%|                               | 338/1000 [03:19<05:42,  1.93it/s]Processing:  34%|                               | 339/1000 [03:19<05:46,  1.91it/s]Processing:  34%|                               | 340/1000 [03:20<05:34,  1.97it/s]Processing:  34%|                               | 341/1000 [03:21<06:15,  1.76it/s]Processing:  34%|                               | 342/1000 [03:21<06:19,  1.73it/s]Processing:  34%|                               | 343/1000 [03:22<06:07,  1.79it/s]Processing:  34%|                               | 344/1000 [03:22<05:40,  1.93it/s]Processing:  34%|                               | 345/1000 [03:23<05:53,  1.85it/s]Processing:  35%|                               | 346/1000 [03:23<05:44,  1.90it/s]Processing:  35%|                               | 347/1000 [03:24<05:28,  1.99it/s]Processing:  35%|                               | 348/1000 [03:24<05:41,  1.91it/s]Processing:  35%|                               | 349/1000 [03:25<05:24,  2.00it/s]Processing:  35%|                               | 350/1000 [03:25<05:16,  2.05it/s]Processing:  35%|                               | 351/1000 [03:26<05:12,  2.08it/s]Processing:  35%|                               | 352/1000 [03:26<05:54,  1.83it/s]Processing:  35%|                               | 353/1000 [03:27<05:52,  1.83it/s]Processing:  35%|                               | 354/1000 [03:27<05:32,  1.94it/s]Processing:  36%|                               | 355/1000 [03:28<05:32,  1.94it/s]Processing:  36%|                               | 356/1000 [03:29<06:19,  1.70it/s]Processing:  36%|                              | 357/1000 [03:29<05:55,  1.81it/s]Processing:  36%|                              | 358/1000 [03:29<05:27,  1.96it/s]Processing:  36%|                              | 359/1000 [03:30<05:22,  1.98it/s]Processing:  36%|                              | 360/1000 [03:30<05:25,  1.97it/s]Processing:  36%|                              | 361/1000 [03:31<05:25,  1.96it/s]Processing:  36%|                              | 362/1000 [03:31<05:30,  1.93it/s]Processing:  36%|                              | 363/1000 [03:32<05:26,  1.95it/s]Processing:  36%|                              | 364/1000 [03:33<05:51,  1.81it/s]Processing:  36%|                              | 365/1000 [03:33<05:42,  1.85it/s]Processing:  37%|                              | 366/1000 [03:34<05:28,  1.93it/s]Processing:  37%|                              | 367/1000 [03:34<06:32,  1.61it/s]Processing:  37%|                              | 368/1000 [03:35<06:06,  1.72it/s]Processing:  37%|                              | 369/1000 [03:35<05:38,  1.87it/s]Processing:  37%|                              | 370/1000 [03:36<05:18,  1.98it/s]Processing:  37%|                              | 371/1000 [03:36<05:19,  1.97it/s]Processing:  37%|                              | 372/1000 [03:37<05:04,  2.06it/s]Processing:  37%|                              | 373/1000 [03:37<04:57,  2.10it/s]Processing:  37%|                              | 374/1000 [03:38<04:59,  2.09it/s]Processing:  38%|                              | 375/1000 [03:38<05:17,  1.97it/s]Processing:  38%|                              | 376/1000 [03:39<06:48,  1.53it/s]Processing:  38%|                              | 377/1000 [03:40<06:54,  1.50it/s]Processing:  38%|                             | 378/1000 [03:40<06:11,  1.67it/s]Processing:  38%|                             | 379/1000 [03:41<06:02,  1.71it/s]Processing:  38%|                             | 380/1000 [03:41<05:43,  1.80it/s]Processing:  38%|                             | 381/1000 [03:42<05:26,  1.90it/s]Processing:  38%|                             | 382/1000 [03:42<05:29,  1.88it/s]Processing:  38%|                             | 383/1000 [03:43<05:17,  1.95it/s]Processing:  38%|                             | 384/1000 [03:43<05:17,  1.94it/s]Processing:  38%|                             | 385/1000 [03:44<05:03,  2.03it/s]Processing:  39%|                             | 386/1000 [03:45<05:29,  1.86it/s]Processing:  39%|                             | 387/1000 [03:45<05:18,  1.92it/s]Processing:  39%|                             | 388/1000 [03:45<05:01,  2.03it/s]Processing:  39%|                             | 389/1000 [03:46<04:56,  2.06it/s]Processing:  39%|                             | 390/1000 [03:47<05:21,  1.90it/s]Processing:  39%|                             | 391/1000 [03:47<05:26,  1.86it/s]Processing:  39%|                             | 392/1000 [03:47<04:50,  2.10it/s]Processing:  39%|                             | 393/1000 [03:48<04:29,  2.25it/s]Processing:  39%|                             | 394/1000 [03:48<04:11,  2.41it/s]Processing:  40%|                             | 395/1000 [03:48<03:57,  2.54it/s]Processing:  40%|                             | 396/1000 [03:49<03:48,  2.65it/s]Processing:  40%|                             | 397/1000 [03:49<03:37,  2.78it/s]Processing:  40%|                             | 398/1000 [03:50<04:58,  2.02it/s]Processing:  40%|                            | 399/1000 [03:50<04:53,  2.05it/s]Processing:  40%|                            | 400/1000 [03:51<04:44,  2.11it/s]Processing:  40%|                            | 401/1000 [03:51<04:42,  2.12it/s]Processing:  40%|                            | 402/1000 [03:52<04:33,  2.19it/s]Processing:  40%|                            | 403/1000 [03:52<04:35,  2.17it/s]Processing:  40%|                            | 404/1000 [03:53<04:37,  2.15it/s]Processing:  40%|                            | 405/1000 [03:53<04:52,  2.03it/s]Processing:  41%|                            | 406/1000 [03:54<04:25,  2.24it/s]Processing:  41%|                            | 407/1000 [03:54<04:15,  2.32it/s]Processing:  41%|                            | 408/1000 [03:54<04:19,  2.28it/s]Processing:  41%|                            | 409/1000 [03:55<05:04,  1.94it/s]Processing:  41%|                            | 410/1000 [03:56<05:07,  1.92it/s]Processing:  41%|                            | 411/1000 [03:56<05:00,  1.96it/s]Processing:  41%|                            | 412/1000 [03:57<04:52,  2.01it/s]Processing:  41%|                            | 413/1000 [03:57<04:55,  1.99it/s]Processing:  41%|                            | 414/1000 [03:58<04:55,  1.98it/s]Processing:  42%|                            | 415/1000 [03:58<04:43,  2.07it/s]Processing:  42%|                            | 416/1000 [03:59<04:47,  2.03it/s]Processing:  42%|                            | 417/1000 [03:59<05:05,  1.91it/s]Processing:  42%|                            | 418/1000 [04:00<04:50,  2.01it/s]Processing:  42%|                            | 419/1000 [04:00<05:34,  1.74it/s]Processing:  42%|                           | 420/1000 [04:01<05:23,  1.79it/s]Processing:  42%|                           | 421/1000 [04:02<05:46,  1.67it/s]Processing:  42%|                           | 422/1000 [04:02<05:57,  1.62it/s]Processing:  42%|                           | 423/1000 [04:03<06:00,  1.60it/s]Processing:  42%|                           | 424/1000 [04:04<05:58,  1.61it/s]Processing:  42%|                           | 425/1000 [04:04<05:56,  1.61it/s]Processing:  43%|                           | 426/1000 [04:05<05:57,  1.60it/s]Processing:  43%|                           | 427/1000 [04:05<05:31,  1.73it/s]Processing:  43%|                           | 428/1000 [04:06<05:16,  1.81it/s]Processing:  43%|                           | 429/1000 [04:06<05:02,  1.89it/s]Processing:  43%|                           | 430/1000 [04:07<05:05,  1.87it/s]Processing:  43%|                           | 431/1000 [04:07<04:50,  1.96it/s]Processing:  43%|                           | 432/1000 [04:08<04:54,  1.93it/s]Processing:  43%|                           | 433/1000 [04:08<04:52,  1.94it/s]Processing:  43%|                           | 434/1000 [04:09<04:55,  1.91it/s]Processing:  44%|                           | 435/1000 [04:09<04:44,  1.98it/s]Processing:  44%|                           | 436/1000 [04:10<04:32,  2.07it/s]Processing:  44%|                           | 437/1000 [04:10<04:45,  1.97it/s]Processing:  44%|                           | 438/1000 [04:11<04:40,  2.01it/s]Processing:  44%|                           | 439/1000 [04:11<04:36,  2.03it/s]Processing:  44%|                           | 440/1000 [04:12<04:42,  1.98it/s]Processing:  44%|                          | 441/1000 [04:12<04:29,  2.07it/s]Processing:  44%|                          | 442/1000 [04:13<04:30,  2.06it/s]Processing:  44%|                          | 443/1000 [04:13<04:21,  2.13it/s]Processing:  44%|                          | 444/1000 [04:14<04:18,  2.15it/s]Processing:  44%|                          | 445/1000 [04:14<04:18,  2.15it/s]Processing:  45%|                          | 446/1000 [04:15<04:37,  1.99it/s]Processing:  45%|                          | 447/1000 [04:15<04:39,  1.98it/s]Processing:  45%|                          | 448/1000 [04:16<04:43,  1.95it/s]Processing:  45%|                          | 449/1000 [04:16<04:35,  2.00it/s]Processing:  45%|                          | 450/1000 [04:17<04:25,  2.07it/s]Processing:  45%|                          | 451/1000 [04:17<04:27,  2.06it/s]Processing:  45%|                          | 452/1000 [04:18<04:33,  2.01it/s]Processing:  45%|                          | 453/1000 [04:18<04:31,  2.02it/s]Processing:  45%|                          | 454/1000 [04:19<05:17,  1.72it/s]Processing:  46%|                          | 455/1000 [04:19<05:00,  1.82it/s]Processing:  46%|                          | 456/1000 [04:20<04:35,  1.98it/s]Processing:  46%|                          | 457/1000 [04:20<04:29,  2.01it/s]Processing:  46%|                          | 458/1000 [04:21<04:15,  2.12it/s]Processing:  46%|                          | 459/1000 [04:21<04:14,  2.13it/s]Processing:  46%|                          | 460/1000 [04:22<04:25,  2.03it/s]Processing:  46%|                         | 461/1000 [04:22<04:19,  2.08it/s]Processing:  46%|                         | 462/1000 [04:23<04:20,  2.07it/s]Processing:  46%|                         | 463/1000 [04:23<04:31,  1.98it/s]Processing:  46%|                         | 464/1000 [04:24<04:29,  1.99it/s]Processing:  46%|                         | 465/1000 [04:24<04:30,  1.98it/s]Processing:  47%|                         | 466/1000 [04:25<04:16,  2.08it/s]Processing:  47%|                         | 467/1000 [04:25<04:14,  2.10it/s]Processing:  47%|                         | 468/1000 [04:26<04:12,  2.10it/s]Processing:  47%|                         | 469/1000 [04:26<04:09,  2.13it/s]Processing:  47%|                         | 470/1000 [04:26<04:08,  2.13it/s]Processing:  47%|                         | 471/1000 [04:27<04:01,  2.19it/s]Processing:  47%|                         | 472/1000 [04:27<03:57,  2.22it/s]Processing:  47%|                         | 473/1000 [04:28<03:51,  2.28it/s]Processing:  47%|                         | 474/1000 [04:28<03:55,  2.23it/s]Processing:  48%|                         | 475/1000 [04:29<03:56,  2.22it/s]Processing:  48%|                         | 476/1000 [04:29<03:52,  2.26it/s]Processing:  48%|                         | 477/1000 [04:30<04:23,  1.98it/s]Processing:  48%|                         | 478/1000 [04:30<04:25,  1.97it/s]Processing:  48%|                         | 479/1000 [04:31<04:30,  1.93it/s]Processing:  48%|                         | 480/1000 [04:31<04:21,  1.99it/s]Processing:  48%|                         | 481/1000 [04:32<04:16,  2.03it/s]Processing:  48%|                        | 482/1000 [04:32<04:05,  2.11it/s]Processing:  48%|                        | 483/1000 [04:33<04:12,  2.05it/s]Processing:  48%|                        | 484/1000 [04:33<04:10,  2.06it/s]Processing:  48%|                        | 485/1000 [04:34<03:58,  2.16it/s]Processing:  49%|                        | 486/1000 [04:34<04:02,  2.12it/s]Processing:  49%|                        | 487/1000 [04:35<04:01,  2.12it/s]Processing:  49%|                        | 488/1000 [04:35<04:00,  2.13it/s]Processing:  49%|                        | 489/1000 [04:36<04:57,  1.72it/s]Processing:  49%|                        | 490/1000 [04:36<04:38,  1.83it/s]Processing:  49%|                        | 491/1000 [04:37<04:26,  1.91it/s]Processing:  49%|                        | 492/1000 [04:37<04:18,  1.97it/s]Processing:  49%|                        | 493/1000 [04:38<04:24,  1.92it/s]Processing:  49%|                        | 494/1000 [04:38<04:14,  1.99it/s]Processing:  50%|                        | 495/1000 [04:39<04:38,  1.82it/s]Processing:  50%|                        | 496/1000 [04:39<04:18,  1.95it/s]Processing:  50%|                        | 497/1000 [04:40<04:05,  2.05it/s]Processing:  50%|                        | 498/1000 [04:40<03:52,  2.16it/s]Processing:  50%|                        | 499/1000 [04:41<03:52,  2.15it/s]Processing:  50%|                        | 500/1000 [04:41<03:52,  2.15it/s]Processing:  50%|                        | 501/1000 [04:42<04:01,  2.07it/s]Processing:  50%|                        | 502/1000 [04:42<04:02,  2.06it/s]Processing:  50%|                       | 503/1000 [04:43<04:52,  1.70it/s]Processing:  50%|                       | 504/1000 [04:43<04:28,  1.85it/s]Processing:  50%|                       | 505/1000 [04:44<04:12,  1.96it/s]Processing:  51%|                       | 506/1000 [04:44<04:06,  2.01it/s]Processing:  51%|                       | 507/1000 [04:45<03:52,  2.12it/s]Processing:  51%|                      | 508/1000 [05:09<1:03:24,  7.73s/it]Processing:  51%|                       | 509/1000 [05:10<45:31,  5.56s/it]Processing:  51%|                       | 510/1000 [05:10<32:47,  4.02s/it]Processing:  51%|                       | 511/1000 [05:11<24:55,  3.06s/it]Processing:  51%|                       | 512/1000 [05:12<18:27,  2.27s/it]Processing:  51%|                       | 513/1000 [05:12<14:00,  1.73s/it]Processing:  51%|                       | 514/1000 [05:12<10:59,  1.36s/it]Processing:  52%|                       | 515/1000 [05:13<08:53,  1.10s/it]Processing:  52%|                       | 516/1000 [05:13<07:19,  1.10it/s]Processing:  52%|                       | 517/1000 [05:14<06:12,  1.30it/s]Processing:  52%|                       | 518/1000 [05:15<05:55,  1.35it/s]Processing:  52%|                       | 519/1000 [05:15<05:25,  1.48it/s]Processing:  52%|                       | 520/1000 [05:16<05:12,  1.54it/s]Processing:  52%|                       | 521/1000 [05:16<04:51,  1.64it/s]Processing:  52%|                       | 522/1000 [05:17<04:37,  1.72it/s]Processing:  52%|                       | 523/1000 [05:17<04:20,  1.83it/s]Processing:  52%|                      | 524/1000 [05:18<04:15,  1.87it/s]Processing:  52%|                      | 525/1000 [05:18<04:04,  1.94it/s]Processing:  53%|                      | 526/1000 [05:19<03:57,  2.00it/s]Processing:  53%|                      | 527/1000 [05:19<03:51,  2.04it/s]Processing:  53%|                      | 528/1000 [05:20<04:07,  1.91it/s]Processing:  53%|                      | 529/1000 [05:20<04:06,  1.91it/s]Processing:  53%|                      | 530/1000 [05:21<04:06,  1.91it/s]Processing:  53%|                      | 531/1000 [05:21<04:03,  1.92it/s]Processing:  53%|                      | 532/1000 [05:22<04:01,  1.94it/s]Processing:  53%|                      | 533/1000 [05:22<04:07,  1.89it/s]Processing:  53%|                      | 534/1000 [05:23<03:58,  1.96it/s]Processing:  54%|                      | 535/1000 [05:23<03:49,  2.03it/s]Processing:  54%|                      | 536/1000 [05:24<03:51,  2.00it/s]Processing:  54%|                      | 537/1000 [05:24<03:54,  1.97it/s]Processing:  54%|                      | 538/1000 [05:25<03:55,  1.96it/s]Processing:  54%|                      | 539/1000 [05:25<04:05,  1.88it/s]Processing:  54%|                      | 540/1000 [05:26<03:56,  1.95it/s]Processing:  54%|                      | 541/1000 [05:26<03:56,  1.94it/s]Processing:  54%|                      | 542/1000 [05:27<03:45,  2.03it/s]Processing:  54%|                      | 543/1000 [05:27<03:57,  1.93it/s]Processing:  54%|                      | 544/1000 [05:28<04:32,  1.67it/s]Processing:  55%|                     | 545/1000 [05:29<04:14,  1.79it/s]Processing:  55%|                     | 546/1000 [05:29<04:06,  1.84it/s]Processing:  55%|                     | 547/1000 [05:30<03:59,  1.89it/s]Processing:  55%|                     | 548/1000 [05:30<03:50,  1.96it/s]Processing:  55%|                     | 549/1000 [05:31<03:50,  1.96it/s]Processing:  55%|                     | 550/1000 [05:31<03:49,  1.96it/s]Processing:  55%|                     | 551/1000 [05:32<03:38,  2.06it/s]Processing:  55%|                     | 552/1000 [05:32<03:35,  2.08it/s]Processing:  55%|                     | 553/1000 [05:32<03:29,  2.14it/s]Processing:  55%|                     | 554/1000 [05:33<03:27,  2.15it/s]Processing:  56%|                     | 555/1000 [05:33<03:23,  2.19it/s]Processing:  56%|                     | 556/1000 [05:34<03:28,  2.13it/s]Processing:  56%|                     | 557/1000 [05:34<03:31,  2.10it/s]Processing:  56%|                     | 558/1000 [05:35<03:24,  2.16it/s]Processing:  56%|                     | 559/1000 [05:35<03:25,  2.15it/s]Processing:  56%|                     | 560/1000 [05:36<03:38,  2.01it/s]Processing:  56%|                     | 561/1000 [05:36<03:47,  1.93it/s]Processing:  56%|                     | 562/1000 [05:37<03:50,  1.90it/s]Processing:  56%|                     | 563/1000 [05:37<03:42,  1.96it/s]Processing:  56%|                     | 564/1000 [05:38<03:37,  2.01it/s]Processing:  56%|                     | 565/1000 [05:38<03:25,  2.12it/s]Processing:  57%|                    | 566/1000 [05:39<03:28,  2.08it/s]Processing:  57%|                    | 567/1000 [05:39<03:42,  1.95it/s]Processing:  57%|                    | 568/1000 [05:40<03:43,  1.93it/s]Processing:  57%|                    | 569/1000 [05:40<03:45,  1.91it/s]Processing:  57%|                    | 570/1000 [05:41<03:47,  1.89it/s]Processing:  57%|                    | 571/1000 [05:42<04:35,  1.56it/s]Processing:  57%|                    | 572/1000 [05:43<05:14,  1.36it/s]Processing:  57%|                    | 573/1000 [05:43<04:48,  1.48it/s]Processing:  57%|                    | 574/1000 [05:44<04:32,  1.56it/s]Processing:  57%|                    | 575/1000 [05:45<04:32,  1.56it/s]Processing:  58%|                    | 576/1000 [05:45<04:24,  1.60it/s]Processing:  58%|                    | 577/1000 [05:46<04:04,  1.73it/s]Processing:  58%|                    | 578/1000 [05:46<03:54,  1.80it/s]Processing:  58%|                    | 579/1000 [05:47<03:49,  1.84it/s]Processing:  58%|                    | 580/1000 [05:47<03:47,  1.85it/s]Processing:  58%|                    | 581/1000 [05:48<03:34,  1.95it/s]Processing:  58%|                    | 582/1000 [05:48<03:37,  1.92it/s]Processing:  58%|                    | 583/1000 [05:49<03:44,  1.85it/s]Processing:  58%|                    | 584/1000 [05:49<03:44,  1.85it/s]Processing:  58%|                    | 585/1000 [05:50<03:53,  1.78it/s]Processing:  59%|                   | 586/1000 [05:50<03:49,  1.80it/s]Processing:  59%|                   | 587/1000 [05:51<04:27,  1.55it/s]Processing:  59%|                   | 588/1000 [05:52<04:00,  1.72it/s]Processing:  59%|                   | 589/1000 [05:52<03:41,  1.86it/s]Processing:  59%|                   | 590/1000 [05:53<03:31,  1.94it/s]Processing:  59%|                   | 591/1000 [05:53<03:33,  1.92it/s]Processing:  59%|                   | 592/1000 [05:54<03:26,  1.98it/s]Processing:  59%|                   | 593/1000 [05:54<03:20,  2.03it/s]Processing:  59%|                   | 594/1000 [05:55<03:16,  2.06it/s]Processing:  60%|                   | 595/1000 [05:55<03:19,  2.03it/s]Processing:  60%|                   | 596/1000 [05:56<03:18,  2.03it/s]Processing:  60%|                   | 597/1000 [05:56<03:23,  1.98it/s]Processing:  60%|                   | 598/1000 [05:57<03:15,  2.06it/s]Processing:  60%|                   | 599/1000 [05:57<03:12,  2.08it/s]Processing:  60%|                   | 600/1000 [05:57<03:10,  2.10it/s]Processing:  60%|                   | 601/1000 [05:58<03:30,  1.90it/s]Processing:  60%|                   | 602/1000 [05:59<03:22,  1.96it/s]Processing:  60%|                   | 603/1000 [05:59<03:22,  1.96it/s]Processing:  60%|                   | 604/1000 [06:00<03:17,  2.00it/s]Processing:  60%|                   | 605/1000 [06:00<03:36,  1.82it/s]Processing:  61%|                   | 606/1000 [06:01<03:31,  1.86it/s]Processing:  61%|                  | 607/1000 [06:01<03:24,  1.92it/s]Processing:  61%|                  | 608/1000 [06:02<03:19,  1.96it/s]Processing:  61%|                  | 609/1000 [06:02<03:17,  1.98it/s]Processing:  61%|                  | 610/1000 [06:03<03:07,  2.08it/s]Processing:  61%|                  | 611/1000 [06:03<03:13,  2.01it/s]Processing:  61%|                  | 612/1000 [06:04<03:39,  1.77it/s]Processing:  61%|                  | 613/1000 [06:04<03:39,  1.76it/s]Processing:  61%|                  | 614/1000 [06:05<03:48,  1.69it/s]Processing:  62%|                  | 615/1000 [06:06<03:42,  1.73it/s]Processing:  62%|                  | 616/1000 [06:06<03:27,  1.85it/s]Processing:  62%|                  | 617/1000 [06:07<03:09,  2.02it/s]Processing:  62%|                  | 618/1000 [06:07<03:02,  2.10it/s]Processing:  62%|                  | 619/1000 [06:07<02:54,  2.18it/s]Processing:  62%|                  | 620/1000 [06:08<02:53,  2.19it/s]Processing:  62%|                  | 621/1000 [06:08<02:52,  2.20it/s]Processing:  62%|                  | 622/1000 [06:09<02:47,  2.26it/s]Processing:  62%|                  | 623/1000 [06:09<02:47,  2.25it/s]Processing:  62%|                  | 624/1000 [06:10<02:47,  2.25it/s]Processing:  62%|                  | 625/1000 [06:10<02:46,  2.25it/s]Processing:  63%|                  | 626/1000 [06:10<02:42,  2.30it/s]Processing:  63%|                  | 627/1000 [06:11<02:39,  2.34it/s]Processing:  63%|                 | 628/1000 [06:11<02:43,  2.28it/s]Processing:  63%|                 | 629/1000 [06:12<02:52,  2.16it/s]Processing:  63%|                 | 630/1000 [06:12<02:55,  2.11it/s]Processing:  63%|                 | 631/1000 [06:13<02:50,  2.17it/s]Processing:  63%|                 | 632/1000 [06:37<47:16,  7.71s/it]Processing:  63%|                 | 633/1000 [06:38<33:50,  5.53s/it]Processing:  63%|                 | 634/1000 [06:38<24:28,  4.01s/it]Processing:  64%|                 | 635/1000 [06:39<17:57,  2.95s/it]Processing:  64%|                 | 636/1000 [06:39<13:24,  2.21s/it]Processing:  64%|                 | 637/1000 [06:40<10:41,  1.77s/it]Processing:  64%|                 | 638/1000 [06:40<08:22,  1.39s/it]Processing:  64%|                 | 639/1000 [06:41<07:17,  1.21s/it]Processing:  64%|                 | 640/1000 [06:42<05:49,  1.03it/s]Processing:  64%|                 | 641/1000 [06:42<05:06,  1.17it/s]Processing:  64%|                 | 642/1000 [06:43<04:18,  1.38it/s]Processing:  64%|                 | 643/1000 [06:43<03:52,  1.54it/s]Processing:  64%|                 | 644/1000 [06:44<03:59,  1.48it/s]Processing:  64%|                 | 645/1000 [06:44<03:37,  1.63it/s]Processing:  65%|                 | 646/1000 [06:45<03:17,  1.79it/s]Processing:  65%|                 | 647/1000 [06:45<03:03,  1.92it/s]Processing:  65%|                 | 648/1000 [06:46<03:01,  1.94it/s]Processing:  65%|                | 649/1000 [06:46<02:58,  1.97it/s]Processing:  65%|                | 650/1000 [06:47<03:01,  1.93it/s]Processing:  65%|                | 651/1000 [06:48<03:27,  1.68it/s]Processing:  65%|                | 652/1000 [06:48<03:14,  1.79it/s]Processing:  65%|                | 653/1000 [06:49<03:07,  1.86it/s]Processing:  65%|                | 654/1000 [06:49<02:54,  1.99it/s]Processing:  66%|                | 655/1000 [06:49<02:52,  2.00it/s]Processing:  66%|                | 656/1000 [06:50<02:49,  2.03it/s]Processing:  66%|                | 657/1000 [06:50<02:55,  1.96it/s]Processing:  66%|                | 658/1000 [06:51<03:04,  1.85it/s]Processing:  66%|                | 659/1000 [06:52<03:04,  1.85it/s]Processing:  66%|                | 660/1000 [06:52<03:03,  1.86it/s]Processing:  66%|                | 661/1000 [06:53<02:59,  1.89it/s]Processing:  66%|                | 662/1000 [06:53<02:51,  1.97it/s]Processing:  66%|                | 663/1000 [06:54<02:56,  1.91it/s]Processing:  66%|                | 664/1000 [06:54<02:56,  1.90it/s]Processing:  66%|                | 665/1000 [06:55<02:51,  1.95it/s]Processing:  67%|                | 666/1000 [06:55<03:12,  1.74it/s]Processing:  67%|                | 667/1000 [06:56<03:36,  1.54it/s]Processing:  67%|                | 668/1000 [06:57<03:18,  1.67it/s]Processing:  67%|                | 669/1000 [06:57<03:05,  1.78it/s]Processing:  67%|               | 670/1000 [06:58<02:53,  1.91it/s]Processing:  67%|               | 671/1000 [06:58<02:44,  2.01it/s]Processing:  67%|               | 672/1000 [06:59<02:41,  2.04it/s]Processing:  67%|               | 673/1000 [06:59<02:36,  2.09it/s]Processing:  67%|               | 674/1000 [07:00<03:02,  1.79it/s]Processing:  68%|               | 675/1000 [07:00<02:46,  1.95it/s]Processing:  68%|               | 676/1000 [07:01<02:47,  1.94it/s]Processing:  68%|               | 677/1000 [07:01<03:14,  1.66it/s]Processing:  68%|               | 678/1000 [07:02<03:04,  1.75it/s]Processing:  68%|               | 679/1000 [07:02<02:47,  1.91it/s]Processing:  68%|               | 680/1000 [07:03<02:41,  1.98it/s]Processing:  68%|               | 681/1000 [07:03<02:35,  2.05it/s]Processing:  68%|               | 682/1000 [07:04<03:08,  1.69it/s]Processing:  68%|               | 683/1000 [07:05<02:54,  1.82it/s]Processing:  68%|               | 684/1000 [07:05<02:42,  1.94it/s]Processing:  68%|               | 685/1000 [07:06<03:06,  1.69it/s]Processing:  69%|               | 686/1000 [07:06<02:48,  1.87it/s]Processing:  69%|               | 687/1000 [07:07<03:01,  1.72it/s]Processing:  69%|               | 688/1000 [07:07<02:54,  1.79it/s]Processing:  69%|               | 689/1000 [07:08<02:47,  1.86it/s]Processing:  69%|               | 690/1000 [07:08<02:44,  1.89it/s]Processing:  69%|              | 691/1000 [07:09<02:45,  1.86it/s]Processing:  69%|              | 692/1000 [07:09<02:35,  1.98it/s]Processing:  69%|              | 693/1000 [07:10<02:31,  2.03it/s]Processing:  69%|              | 694/1000 [07:10<02:25,  2.11it/s]Processing:  70%|              | 695/1000 [07:11<02:24,  2.12it/s]Processing:  70%|              | 696/1000 [07:11<02:29,  2.04it/s]Processing:  70%|              | 697/1000 [07:12<02:26,  2.07it/s]Processing:  70%|              | 698/1000 [07:12<02:33,  1.97it/s]Processing:  70%|              | 699/1000 [07:13<02:32,  1.98it/s]Processing:  70%|              | 700/1000 [07:14<03:00,  1.66it/s]Processing:  70%|              | 701/1000 [07:14<02:55,  1.70it/s]Processing:  70%|              | 702/1000 [07:15<03:00,  1.65it/s]Processing:  70%|              | 703/1000 [07:15<02:45,  1.80it/s]Processing:  70%|              | 704/1000 [07:16<02:42,  1.83it/s]Processing:  70%|              | 705/1000 [07:16<02:42,  1.82it/s]Processing:  71%|              | 706/1000 [07:17<02:35,  1.89it/s]Processing:  71%|              | 707/1000 [07:17<02:39,  1.84it/s]Processing:  71%|              | 708/1000 [07:18<02:31,  1.92it/s]Processing:  71%|              | 709/1000 [07:18<02:36,  1.86it/s]Processing:  71%|              | 710/1000 [07:19<02:40,  1.81it/s]Processing:  71%|             | 711/1000 [07:19<02:30,  1.91it/s]Processing:  71%|             | 712/1000 [07:20<02:26,  1.96it/s]Processing:  71%|             | 713/1000 [07:21<02:53,  1.65it/s]Processing:  71%|             | 714/1000 [07:22<03:08,  1.52it/s]Processing:  72%|             | 715/1000 [07:22<03:11,  1.49it/s]Processing:  72%|             | 716/1000 [07:23<03:45,  1.26it/s]Processing:  72%|             | 717/1000 [07:24<03:17,  1.43it/s]Processing:  72%|             | 718/1000 [07:24<02:54,  1.61it/s]Processing:  72%|             | 719/1000 [07:25<02:43,  1.72it/s]Processing:  72%|             | 720/1000 [07:26<02:58,  1.57it/s]Processing:  72%|             | 721/1000 [07:26<02:44,  1.70it/s]Processing:  72%|             | 722/1000 [07:26<02:36,  1.78it/s]Processing:  72%|             | 723/1000 [07:27<02:30,  1.84it/s]Processing:  72%|             | 724/1000 [07:28<02:32,  1.81it/s]Processing:  72%|             | 725/1000 [07:28<02:32,  1.80it/s]Processing:  73%|             | 726/1000 [07:29<02:30,  1.82it/s]Processing:  73%|             | 727/1000 [07:29<02:28,  1.83it/s]Processing:  73%|             | 728/1000 [07:30<02:31,  1.79it/s]Processing:  73%|             | 729/1000 [07:30<02:28,  1.82it/s]Processing:  73%|             | 730/1000 [07:31<02:21,  1.91it/s]Processing:  73%|             | 731/1000 [07:32<02:46,  1.62it/s]Processing:  73%|            | 732/1000 [07:32<02:27,  1.81it/s]Processing:  73%|            | 733/1000 [07:33<02:22,  1.87it/s]Processing:  73%|            | 734/1000 [07:33<02:11,  2.02it/s]Processing:  74%|            | 735/1000 [07:33<02:13,  1.99it/s]Processing:  74%|            | 736/1000 [07:34<02:10,  2.02it/s]Processing:  74%|            | 737/1000 [07:34<02:10,  2.02it/s]Processing:  74%|            | 738/1000 [07:35<02:10,  2.00it/s]Processing:  74%|            | 739/1000 [07:35<02:03,  2.12it/s]Processing:  74%|            | 740/1000 [07:36<02:06,  2.06it/s]Processing:  74%|            | 741/1000 [07:36<02:09,  2.00it/s]Processing:  74%|            | 742/1000 [07:37<02:33,  1.68it/s]Processing:  74%|            | 743/1000 [07:38<02:56,  1.46it/s]Processing:  74%|            | 744/1000 [07:39<03:05,  1.38it/s]Processing:  74%|            | 745/1000 [07:39<02:54,  1.46it/s]Processing:  75%|            | 746/1000 [07:40<02:44,  1.54it/s]Processing:  75%|            | 747/1000 [07:41<02:35,  1.62it/s]Processing:  75%|            | 748/1000 [07:41<02:33,  1.64it/s]Processing:  75%|            | 749/1000 [07:42<02:23,  1.75it/s]Processing:  75%|            | 750/1000 [07:42<02:21,  1.77it/s]Processing:  75%|            | 751/1000 [07:43<02:21,  1.76it/s]Processing:  75%|            | 752/1000 [07:43<02:16,  1.82it/s]Processing:  75%|           | 753/1000 [07:44<02:12,  1.86it/s]Processing:  75%|           | 754/1000 [07:44<02:04,  1.98it/s]Processing:  76%|           | 755/1000 [07:45<01:58,  2.07it/s]Processing:  76%|           | 756/1000 [07:45<02:05,  1.95it/s]Processing:  76%|           | 757/1000 [07:46<02:26,  1.66it/s]Processing:  76%|           | 758/1000 [07:47<02:25,  1.66it/s]Processing:  76%|           | 759/1000 [07:47<02:27,  1.64it/s]Processing:  76%|           | 760/1000 [07:48<02:43,  1.47it/s]Processing:  76%|           | 761/1000 [07:49<02:47,  1.43it/s]Processing:  76%|           | 762/1000 [07:50<02:51,  1.39it/s]Processing:  76%|           | 763/1000 [07:50<02:34,  1.53it/s]Processing:  76%|           | 764/1000 [07:51<02:26,  1.61it/s]Processing:  76%|           | 765/1000 [07:51<02:16,  1.72it/s]Processing:  77%|           | 766/1000 [07:52<02:08,  1.82it/s]Processing:  77%|           | 767/1000 [07:52<02:22,  1.63it/s]Processing:  77%|           | 768/1000 [07:53<02:15,  1.71it/s]Processing:  77%|           | 769/1000 [07:53<02:08,  1.80it/s]Processing:  77%|           | 770/1000 [07:54<02:06,  1.82it/s]Processing:  77%|           | 771/1000 [07:55<02:10,  1.76it/s]Processing:  77%|           | 772/1000 [07:55<02:13,  1.71it/s]Processing:  77%|           | 773/1000 [07:56<02:11,  1.72it/s]Processing:  77%|          | 774/1000 [07:57<02:28,  1.52it/s]Processing:  78%|          | 775/1000 [07:57<02:19,  1.61it/s]Processing:  78%|          | 776/1000 [07:58<02:14,  1.66it/s]Processing:  78%|          | 777/1000 [07:58<02:08,  1.73it/s]Processing:  78%|          | 778/1000 [07:59<01:48,  2.04it/s]Processing:  78%|          | 779/1000 [07:59<01:33,  2.36it/s]Processing:  78%|          | 780/1000 [07:59<01:23,  2.64it/s]Processing:  78%|          | 781/1000 [07:59<01:18,  2.79it/s]Processing:  78%|          | 782/1000 [08:00<01:18,  2.79it/s]Processing:  78%|          | 783/1000 [08:00<01:13,  2.96it/s]Processing:  78%|          | 784/1000 [08:01<01:36,  2.25it/s]Processing:  78%|          | 785/1000 [08:01<01:46,  2.03it/s]Processing:  79%|          | 786/1000 [08:02<01:57,  1.82it/s]Processing:  79%|          | 787/1000 [08:02<01:49,  1.95it/s]Processing:  79%|          | 788/1000 [08:03<01:47,  1.97it/s]Processing:  79%|          | 789/1000 [08:03<01:41,  2.07it/s]Processing:  79%|          | 790/1000 [08:04<01:51,  1.89it/s]Processing:  79%|          | 791/1000 [08:04<01:46,  1.97it/s]Processing:  79%|          | 792/1000 [08:05<01:42,  2.02it/s]Processing:  79%|          | 793/1000 [08:06<02:02,  1.69it/s]Processing:  79%|          | 794/1000 [08:07<02:23,  1.44it/s]Processing:  80%|         | 795/1000 [08:07<02:20,  1.45it/s]Processing:  80%|         | 796/1000 [08:08<02:16,  1.49it/s]Processing:  80%|         | 797/1000 [08:09<02:30,  1.35it/s]Processing:  80%|         | 798/1000 [08:10<02:39,  1.27it/s]Processing:  80%|         | 799/1000 [08:10<02:23,  1.40it/s]Processing:  80%|         | 800/1000 [08:11<02:13,  1.50it/s]Processing:  80%|         | 801/1000 [08:12<02:11,  1.52it/s]Processing:  80%|         | 802/1000 [08:12<02:01,  1.63it/s]Processing:  80%|         | 803/1000 [08:13<02:00,  1.64it/s]Processing:  80%|         | 804/1000 [08:13<01:49,  1.80it/s]Processing:  80%|         | 805/1000 [08:13<01:41,  1.92it/s]Processing:  81%|         | 806/1000 [08:14<01:33,  2.08it/s]Processing:  81%|         | 807/1000 [08:15<01:48,  1.78it/s]Processing:  81%|         | 808/1000 [08:15<01:39,  1.94it/s]Processing:  81%|         | 809/1000 [08:15<01:33,  2.05it/s]Processing:  81%|         | 810/1000 [08:16<01:45,  1.79it/s]Processing:  81%|         | 811/1000 [08:17<01:46,  1.78it/s]Processing:  81%|         | 812/1000 [08:17<01:40,  1.88it/s]Processing:  81%|         | 813/1000 [08:18<01:38,  1.90it/s]Processing:  81%|         | 814/1000 [08:18<01:34,  1.96it/s]Processing:  82%|         | 815/1000 [08:19<01:31,  2.01it/s]Processing:  82%|        | 816/1000 [08:19<01:35,  1.93it/s]Processing:  82%|        | 817/1000 [08:20<01:36,  1.90it/s]Processing:  82%|        | 818/1000 [08:21<01:48,  1.68it/s]Processing:  82%|        | 819/1000 [08:21<01:40,  1.79it/s]Processing:  82%|        | 820/1000 [08:22<01:36,  1.86it/s]Processing:  82%|        | 821/1000 [08:22<01:33,  1.91it/s]Processing:  82%|        | 822/1000 [08:22<01:29,  2.00it/s]Processing:  82%|        | 823/1000 [08:23<01:27,  2.02it/s]Processing:  82%|        | 824/1000 [08:23<01:24,  2.08it/s]Processing:  82%|        | 825/1000 [08:24<01:23,  2.08it/s]Processing:  83%|        | 826/1000 [08:24<01:25,  2.03it/s]Processing:  83%|        | 827/1000 [08:25<01:31,  1.88it/s]Processing:  83%|        | 828/1000 [08:26<01:33,  1.83it/s]Processing:  83%|        | 829/1000 [08:26<01:50,  1.55it/s]Processing:  83%|        | 830/1000 [08:27<01:40,  1.69it/s]Processing:  83%|        | 831/1000 [08:27<01:36,  1.75it/s]Processing:  83%|        | 832/1000 [08:28<01:30,  1.85it/s]Processing:  83%|        | 833/1000 [08:28<01:27,  1.90it/s]Processing:  83%|        | 834/1000 [08:29<01:29,  1.86it/s]Processing:  84%|        | 835/1000 [08:29<01:24,  1.96it/s]Processing:  84%|       | 836/1000 [08:30<01:18,  2.10it/s]Processing:  84%|       | 837/1000 [08:30<01:10,  2.31it/s]Processing:  84%|       | 838/1000 [08:30<01:01,  2.63it/s]Processing:  84%|       | 839/1000 [08:31<01:06,  2.42it/s]Processing:  84%|       | 840/1000 [08:32<01:25,  1.87it/s]Processing:  84%|       | 841/1000 [08:32<01:31,  1.73it/s]Processing:  84%|       | 842/1000 [08:33<01:44,  1.51it/s]Processing:  84%|       | 843/1000 [08:34<01:46,  1.48it/s]Processing:  84%|       | 844/1000 [08:35<01:42,  1.53it/s]Processing:  84%|       | 845/1000 [08:35<01:41,  1.53it/s]Processing:  85%|       | 846/1000 [08:36<01:39,  1.55it/s]Processing:  85%|       | 847/1000 [08:36<01:27,  1.75it/s]Processing:  85%|       | 848/1000 [08:37<01:23,  1.82it/s]Processing:  85%|       | 849/1000 [08:37<01:21,  1.85it/s]Processing:  85%|       | 850/1000 [08:38<01:30,  1.65it/s]Processing:  85%|       | 851/1000 [08:39<01:28,  1.68it/s]Processing:  85%|       | 852/1000 [08:39<01:22,  1.78it/s]Processing:  85%|       | 853/1000 [08:39<01:16,  1.93it/s]Processing:  85%|       | 854/1000 [08:40<01:12,  2.03it/s]Processing:  86%|       | 855/1000 [08:40<01:08,  2.12it/s]Processing:  86%|       | 856/1000 [08:41<01:08,  2.10it/s]Processing:  86%|      | 857/1000 [08:41<01:09,  2.05it/s]Processing:  86%|      | 858/1000 [08:42<01:09,  2.04it/s]Processing:  86%|      | 859/1000 [08:42<01:12,  1.93it/s]Processing:  86%|      | 860/1000 [08:43<01:12,  1.94it/s]Processing:  86%|      | 861/1000 [08:43<01:10,  1.97it/s]Processing:  86%|      | 862/1000 [08:44<01:15,  1.82it/s]Processing:  86%|      | 863/1000 [08:45<01:22,  1.66it/s]Processing:  86%|      | 864/1000 [08:45<01:21,  1.68it/s]Processing:  86%|      | 865/1000 [08:46<01:30,  1.49it/s]Processing:  87%|      | 866/1000 [08:47<01:32,  1.45it/s]Processing:  87%|      | 867/1000 [08:48<01:34,  1.40it/s]Processing:  87%|      | 868/1000 [08:48<01:36,  1.36it/s]Processing:  87%|      | 869/1000 [08:50<01:52,  1.17it/s]Processing:  87%|      | 870/1000 [08:50<01:51,  1.17it/s]Processing:  87%|      | 871/1000 [08:51<01:46,  1.21it/s]Processing:  87%|      | 872/1000 [08:52<01:51,  1.15it/s]Processing:  87%|      | 873/1000 [08:53<01:36,  1.32it/s]Processing:  87%|      | 874/1000 [08:53<01:27,  1.44it/s]Processing:  88%|      | 875/1000 [08:54<01:20,  1.54it/s]Processing:  88%|      | 876/1000 [08:55<01:25,  1.45it/s]Processing:  88%|      | 877/1000 [08:55<01:26,  1.42it/s]Processing:  88%|     | 878/1000 [08:56<01:15,  1.61it/s]Processing:  88%|     | 879/1000 [08:56<01:09,  1.74it/s]Processing:  88%|     | 880/1000 [08:57<01:07,  1.77it/s]Processing:  88%|     | 881/1000 [08:57<01:01,  1.93it/s]Processing:  88%|     | 882/1000 [08:58<00:59,  1.98it/s]Processing:  88%|     | 883/1000 [08:58<00:54,  2.14it/s]Processing:  88%|     | 884/1000 [09:22<14:30,  7.51s/it]Processing:  88%|     | 885/1000 [09:23<10:30,  5.48s/it]Processing:  89%|     | 886/1000 [09:23<07:32,  3.97s/it]Processing:  89%|     | 887/1000 [09:24<05:28,  2.91s/it]Processing:  89%|     | 888/1000 [09:24<04:07,  2.21s/it]Processing:  89%|     | 889/1000 [09:25<03:08,  1.70s/it]Processing:  89%|     | 890/1000 [09:25<02:26,  1.33s/it]Processing:  89%|     | 891/1000 [09:26<01:56,  1.07s/it]Processing:  89%|     | 892/1000 [09:26<01:36,  1.12it/s]Processing:  89%|     | 893/1000 [09:27<01:20,  1.33it/s]Processing:  89%|     | 894/1000 [09:27<01:10,  1.50it/s]Processing:  90%|     | 895/1000 [09:28<01:06,  1.58it/s]Processing:  90%|     | 896/1000 [09:28<01:00,  1.71it/s]Processing:  90%|     | 897/1000 [09:28<00:56,  1.82it/s]Processing:  90%|     | 898/1000 [09:29<00:52,  1.93it/s]Processing:  90%|    | 899/1000 [09:30<00:56,  1.77it/s]Processing:  90%|    | 900/1000 [09:30<00:50,  1.96it/s]Processing:  90%|    | 901/1000 [09:30<00:50,  1.96it/s]Processing:  90%|    | 902/1000 [09:31<00:50,  1.94it/s]Processing:  90%|    | 903/1000 [09:32<00:50,  1.92it/s]Processing:  90%|    | 904/1000 [09:32<00:48,  1.99it/s]Processing:  90%|    | 905/1000 [09:32<00:47,  2.01it/s]Processing:  91%|    | 906/1000 [09:33<00:46,  2.03it/s]Processing:  91%|    | 907/1000 [09:34<00:47,  1.97it/s]Processing:  91%|    | 908/1000 [09:34<00:48,  1.89it/s]Processing:  91%|    | 909/1000 [09:35<00:47,  1.91it/s]Processing:  91%|    | 910/1000 [09:35<00:44,  2.02it/s]Processing:  91%|    | 911/1000 [09:36<00:44,  2.00it/s]Processing:  91%|    | 912/1000 [09:36<00:44,  1.99it/s]Processing:  91%|    | 913/1000 [09:36<00:37,  2.33it/s]Processing:  91%|    | 914/1000 [09:37<00:33,  2.54it/s]Processing:  92%|    | 915/1000 [09:37<00:31,  2.73it/s]Processing:  92%|    | 916/1000 [09:38<00:39,  2.13it/s]Processing:  92%|    | 917/1000 [09:38<00:41,  1.98it/s]Processing:  92%|    | 918/1000 [09:39<00:42,  1.92it/s]Processing:  92%|    | 919/1000 [09:40<00:48,  1.65it/s]Processing:  92%|   | 920/1000 [09:40<00:40,  2.00it/s]Processing:  92%|   | 921/1000 [09:40<00:34,  2.31it/s]Processing:  92%|   | 922/1000 [09:40<00:31,  2.45it/s]Processing:  92%|   | 923/1000 [09:41<00:33,  2.32it/s]Processing:  92%|   | 924/1000 [09:41<00:33,  2.26it/s]Processing:  92%|   | 925/1000 [09:42<00:33,  2.27it/s]Processing:  93%|   | 926/1000 [09:42<00:33,  2.19it/s]Processing:  93%|   | 927/1000 [09:43<00:34,  2.09it/s]Processing:  93%|   | 928/1000 [09:44<00:38,  1.88it/s]Processing:  93%|   | 929/1000 [09:44<00:37,  1.88it/s]Processing:  93%|   | 930/1000 [09:45<00:36,  1.93it/s]Processing:  93%|   | 931/1000 [09:45<00:34,  2.02it/s]Processing:  93%|   | 932/1000 [09:45<00:31,  2.13it/s]Processing:  93%|   | 933/1000 [09:46<00:38,  1.73it/s]Processing:  93%|   | 934/1000 [09:47<00:37,  1.78it/s]Processing:  94%|   | 935/1000 [09:47<00:34,  1.87it/s]Processing:  94%|   | 936/1000 [09:48<00:34,  1.87it/s]Processing:  94%|   | 937/1000 [09:48<00:32,  1.94it/s]Processing:  94%|   | 938/1000 [09:49<00:30,  2.03it/s]Processing:  94%|   | 939/1000 [09:49<00:29,  2.07it/s]Processing:  94%|   | 940/1000 [09:50<00:29,  2.06it/s]Processing:  94%|  | 941/1000 [09:50<00:29,  2.00it/s]Processing:  94%|  | 942/1000 [09:51<00:29,  1.95it/s]Processing:  94%|  | 943/1000 [09:51<00:29,  1.95it/s]Processing:  94%|  | 944/1000 [09:52<00:28,  1.98it/s]Processing:  94%|  | 945/1000 [09:52<00:28,  1.93it/s]Processing:  95%|  | 946/1000 [09:53<00:31,  1.70it/s]Processing:  95%|  | 947/1000 [09:54<00:30,  1.71it/s]Processing:  95%|  | 948/1000 [09:54<00:31,  1.66it/s]Processing:  95%|  | 949/1000 [09:55<00:31,  1.64it/s]Processing:  95%|  | 950/1000 [09:55<00:29,  1.71it/s]Processing:  95%|  | 951/1000 [09:56<00:29,  1.64it/s]Processing:  95%|  | 952/1000 [09:57<00:29,  1.60it/s]Processing:  95%|  | 953/1000 [09:57<00:28,  1.64it/s]Processing:  95%|  | 954/1000 [09:58<00:27,  1.65it/s]Processing:  96%|  | 955/1000 [09:59<00:28,  1.56it/s]Processing:  96%|  | 956/1000 [09:59<00:27,  1.62it/s]Processing:  96%|  | 957/1000 [10:00<00:29,  1.47it/s]Processing:  96%|  | 958/1000 [10:01<00:28,  1.50it/s]Processing:  96%|  | 959/1000 [10:01<00:25,  1.59it/s]Processing:  96%|  | 960/1000 [10:02<00:23,  1.69it/s]Processing:  96%| | 961/1000 [10:02<00:22,  1.75it/s]Processing:  96%| | 962/1000 [10:03<00:21,  1.81it/s]Processing:  96%| | 963/1000 [10:03<00:19,  1.93it/s]Processing:  96%| | 964/1000 [10:04<00:18,  1.92it/s]Processing:  96%| | 965/1000 [10:04<00:17,  2.01it/s]Processing:  97%| | 966/1000 [10:05<00:17,  1.99it/s]Processing:  97%| | 967/1000 [10:05<00:16,  1.97it/s]Processing:  97%| | 968/1000 [10:06<00:16,  1.96it/s]Processing:  97%| | 969/1000 [10:06<00:17,  1.79it/s]Processing:  97%| | 970/1000 [10:07<00:15,  1.92it/s]Processing:  97%| | 971/1000 [10:07<00:15,  1.93it/s]Processing:  97%| | 972/1000 [10:08<00:14,  1.99it/s]Processing:  97%| | 973/1000 [10:08<00:13,  1.97it/s]Processing:  97%| | 974/1000 [10:09<00:12,  2.01it/s]Processing:  98%| | 975/1000 [10:09<00:11,  2.10it/s]Processing:  98%| | 976/1000 [10:10<00:11,  2.05it/s]Processing:  98%| | 977/1000 [10:10<00:11,  2.03it/s]Processing:  98%| | 978/1000 [10:11<00:10,  2.00it/s]Processing:  98%| | 979/1000 [10:11<00:10,  1.99it/s]Processing:  98%| | 980/1000 [10:12<00:09,  2.07it/s]Processing:  98%| | 981/1000 [10:12<00:09,  2.04it/s]Processing:  98%|| 982/1000 [10:13<00:08,  2.07it/s]Processing:  98%|| 983/1000 [10:13<00:08,  1.98it/s]Processing:  98%|| 984/1000 [10:14<00:08,  1.94it/s]Processing:  98%|| 985/1000 [10:14<00:07,  2.04it/s]Processing:  99%|| 986/1000 [10:15<00:07,  1.98it/s]Processing:  99%|| 987/1000 [10:15<00:06,  2.10it/s]Processing:  99%|| 988/1000 [10:16<00:05,  2.09it/s]Processing:  99%|| 989/1000 [10:16<00:05,  2.15it/s]Processing:  99%|| 990/1000 [10:16<00:04,  2.20it/s]Processing:  99%|| 991/1000 [10:17<00:04,  1.94it/s]Processing:  99%|| 992/1000 [10:18<00:04,  1.99it/s]Processing:  99%|| 993/1000 [10:18<00:03,  2.07it/s]Processing:  99%|| 994/1000 [10:18<00:02,  2.08it/s]Processing: 100%|| 995/1000 [10:19<00:02,  2.09it/s]Processing: 100%|| 996/1000 [10:19<00:01,  2.11it/s]Processing: 100%|| 997/1000 [10:20<00:01,  2.08it/s]Processing: 100%|| 998/1000 [10:20<00:00,  2.41it/s]Processing: 100%|| 999/1000 [10:21<00:00,  2.51it/s]Processing: 100%|| 1000/1000 [10:21<00:00,  2.83it/s]Processing: 100%|| 1000/1000 [10:21<00:00,  1.61it/s]
evaluation output to ./results/jsons/vqav2-29-llava_new_1.6_7-0.2.json
  0%|          | 0/1000 [00:00<?, ?it/s] 62%|   | 624/1000 [00:00<00:00, 6231.73it/s]100%|| 1000/1000 [00:00<00:00, 6257.40it/s]
Time: 2025-06-10d 15:49:05, Version: vqav2-29-llava_new_1.6_7-0.2, Acc: 79.41 write into ./results/result_0.json
